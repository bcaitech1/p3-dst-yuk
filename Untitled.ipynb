{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6aedecbf-5440-4dc4-9e3c-fc51cfbafa16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "\n",
    "import easydict\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from tqdm import tqdm\n",
    "from transformers import AdamW, BertTokenizer, get_linear_schedule_with_warmup\n",
    "\n",
    "from data_utils import (WOSDataset, get_examples_from_dialogues, load_dataset, set_seed,\n",
    "                        seed_everything)\n",
    "from eval_utils import DSTEvaluator\n",
    "from evaluation import _evaluation\n",
    "from inference import inference\n",
    "from preprocessor import TRADEPreprocessor\n",
    "# from my_transformer import Decoder\n",
    "\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e68b5314-df68-4d3b-9117-d6cf165038f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = easydict.EasyDict({\n",
    "    'data_dir' : \"../../input/data/train_dataset\",\n",
    "    'model_dir' : \"results\",\n",
    "    'train_batch_size' : 4,\n",
    "    'eval_batch_size' : 32,\n",
    "    'learning_rate' : 1e-4,\n",
    "    'adam_epsilon' : 1e-8,\n",
    "    'max_grad_norm' : 1.0,\n",
    "    'num_train_epochs' : 30,\n",
    "    'warmup_ratio' : 0.1,\n",
    "    'random_seed' : 42,\n",
    "    'model_name_or_path' : 'dsksd/bert-ko-small-minimal',\n",
    "    'hidden_size' : 768,\n",
    "    'vocab_size' : None,\n",
    "    'hidden_dropout_prob' : 0.1,\n",
    "    'proj_dim' : None,\n",
    "    'teacher_forcing_ratio' : 0.5,\n",
    "    'word_dropout' : 0,\n",
    "    'max_position' : 512,\n",
    "    'attention_drop_out' : 0.1,\n",
    "    'num_attention_heads' : 6,\n",
    "    'ffn_dim' : 768*2,\n",
    "    'num_decoder_layers' : 3\n",
    "    \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20d0fa26-b6ab-44a7-9441-36667ebf25ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(args.model_name_or_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1288f1c3-b90f-4961-b3c3-8e773e785e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "slot_meta = json.load(open(f\"{args.data_dir}/slot_meta.json\"))\n",
    "processor = TRADEPreprocessor(slot_meta, tokenizer, word_dropout_rate = args.word_dropout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9280c57-a8cd-40ea-adb5-fc5f1f96cf69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'##ne none'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_list = [11764,21832,11764]\n",
    "tokenizer.decode(id_list,skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b6d1eda-6dc4-4472-8f7e-118e3c7125a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6301/6301 [00:00<00:00, 11377.65it/s]\n",
      "100%|██████████| 699/699 [00:00<00:00, 2841.56it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\ndev_examples[10] = DSTInputExample(guid='shy-sea-4716:관광_11-2', context_turns=['', '제가 서울을 처음 와봐서 문화 예술과 관련된 곳으로 관광하고 싶은데 어디로 가면 될까요?', '안녕하세요. 관광을 원하시는 지역과 종류가 있으시면 말씀해주세요.', '서울 중앙쪽으로 알려주세요. 종류는 글쎄요 잘 모르겠어요.'], current_turn=['네. 그럼 명동난타극장과 삼성미술관 라움, 정동극장을 추천해드립니다. 어디가 괜찮으세요?', '미술관이 좋을것 같아요. 지하철로 이동하려고 하는데 어디에서 내리면 되나요?'], label=None)\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_file = f\"{args.data_dir}/train_dials.json\"\n",
    "slot_meta = json.load(open(f\"{args.data_dir}/slot_meta.json\"))\n",
    "'''['관광-경치 좋은', '관광-교육적', '관광-도보 가능', '관광-문화 예술', '관광-역사적', '관광-이름', '관광-종류', '관광-주차 가능', '관광-지역', '숙소-가격대', '숙소-도보 가능', '숙소-수영장 유무', '숙소-스파 유무', '숙소-예약 기간', '숙소-예약 명수', '숙소-예약 요일', '숙소-이름', '숙소-인터넷 가능', '숙소-조식 가능', '숙소-종류', '숙소-주차 가능', '숙소-지역', '숙소-헬스장 유무', '숙소-흡연 가능', '식당-가격대', '식당-도보 가능', '식당-야외석 유무', '식당-예약 명수', '식당-예약 시간', '식당-예약 요일', '식당-이름', '식당-인터넷 가능', '식당-종류', '식당-주류 판매', '식당-주차 가능', '식당-지역', '식당-흡연 가능', '지하철-도착지', '지하철-출발 시간', '지하철-출발지', '택시-도착 시간', '택시-도착지', '택시-종류', '택시-출발 시간', '택시-출발지']'''\n",
    "train_data, dev_data, dev_labels = load_dataset(train_data_file)\n",
    "\n",
    "train_examples = get_examples_from_dialogues(\n",
    "    train_data, user_first=False, dialogue_level=False\n",
    ")\n",
    "'''\n",
    "train_examples[10] = DSTInputExample(guid='polished-poetry-0057:관광_9-2', context_turns=['', '쇼핑을 하려는데 서울 서쪽에 있을까요?', '서울 서쪽에 쇼핑이 가능한 곳이라면 노량진 수산물 도매시장이 있습니다.', '오 네 거기 주소 좀 알려주세요.'], current_turn=['노량진 수산물 도매시장의 주소는 서울 동작구 93806입니다.', '알려주시는김에 연락처랑 평점도 좀 알려주세요.'], label=['관광-종류-쇼핑', '관광-지역-서울 서쪽', '관광-이름-노량진 수산물 도매시장'])\n",
    "'''\n",
    "dev_examples = get_examples_from_dialogues(\n",
    "    dev_data, user_first=False, dialogue_level=False\n",
    ")\n",
    "'''\n",
    "dev_examples[10] = DSTInputExample(guid='shy-sea-4716:관광_11-2', context_turns=['', '제가 서울을 처음 와봐서 문화 예술과 관련된 곳으로 관광하고 싶은데 어디로 가면 될까요?', '안녕하세요. 관광을 원하시는 지역과 종류가 있으시면 말씀해주세요.', '서울 중앙쪽으로 알려주세요. 종류는 글쎄요 잘 모르겠어요.'], current_turn=['네. 그럼 명동난타극장과 삼성미술관 라움, 정동극장을 추천해드립니다. 어디가 괜찮으세요?', '미술관이 좋을것 같아요. 지하철로 이동하려고 하는데 어디에서 내리면 되나요?'], label=None)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4690d69-c0f7-4cc0-8d5a-d8ddb490f82a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'각 domain-slot pair를 토크나이징 한다.\\ntokenized_slot_meta[0] = [6728, 21170, 3311, 4112]\\ntokenized_slot_meta[1] = [6728, 6295, 4199, 0]\\ntokenized_slot_meta[2] = [6728, 17502, 6259, 0]\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define Preprocessor\n",
    "tokenizer = BertTokenizer.from_pretrained(args.model_name_or_path)\n",
    "processor = TRADEPreprocessor(slot_meta, tokenizer, word_dropout_rate = args.word_dropout)\n",
    "args.vocab_size = len(tokenizer)\n",
    "args.n_gate = len(processor.gating2id) \n",
    "\n",
    "# Slot Meta tokenizing for the decoder initial inputs\n",
    "tokenized_slot_meta = []\n",
    "for slot in slot_meta:\n",
    "    tokenized_slot_meta.append(\n",
    "        tokenizer.encode(slot.replace(\"-\", \" \"), add_special_tokens=False)\n",
    "    )\n",
    "'''각 domain-slot pair를 토크나이징 한다.\n",
    "tokenized_slot_meta[0] = [6728, 21170, 3311, 4112]\n",
    "tokenized_slot_meta[1] = [6728, 6295, 4199, 0]\n",
    "tokenized_slot_meta[2] = [6728, 17502, 6259, 0]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47f79694-a618-4cea-b5b4-416423a193fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import importlib\n",
    "# import model_transformer\n",
    "# importlib.reload(model_transformer)\n",
    "# from model_transformer import TRADE, masked_cross_entropy_for_value\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# # Model 선언\n",
    "# model = TRADE(args, tokenized_slot_meta)\n",
    "# # model.set_subword_embedding(args.model_name_or_path)  # Subword Embedding 초기화\n",
    "# # print(f\"Subword Embeddings is loaded from {args.model_name_or_path}\")\n",
    "# model.to(device)\n",
    "# print(\"Model is initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47dc9c40-8fcb-4c84-9e02-2423202d494d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (537 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hoho\n"
     ]
    }
   ],
   "source": [
    "# gating 갯수 none, dontcare, ptr\n",
    "\n",
    "# Extracting Featrues\n",
    "train_features = processor.convert_examples_to_features(train_examples)\n",
    "'''train_features[2]\n",
    "OpenVocabDSTFeature(guid='snowy-hat-8324:관광_식당_11-2', input_id=[2, 3, 6265, 6672, 4073, 3249, 4034, 8732, 4292, 6722, 4076, 8553, 3, 11655, 4279, 8553, 18, 6336, 4481, 22014, 6771, 4204, 4112, 8538, 4147, 27233, 35, 18790, 4086, 24, 4469, 10749, 14043, 4006, 4073, 4325, 3311, 4112, 6392, 4110, 2734, 4219, 3249, 4576, 6216, 18, 3, 3311, 4116, 4150, 7149, 18790, 4112, 2633, 4151, 4076, 5240, 4050, 6698, 4467, 4029, 4070, 13177, 4479, 4065, 4150, 35, 3, 6698, 4467, 4029, 4034, 9908, 26885, 11684, 25845, 4204, 10561, 18, 2373, 6289, 4279, 4147, 2054, 3249, 4154, 4161, 10397, 35, 3, 2279, 13090, 4192, 2024, 4112, 6249, 4234, 15532, 4403, 4292, 2010, 4219, 4451, 4112, 4244, 4150, 11431, 4221, 4007, 3249, 16868, 4479, 4150, 3], segment_id=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], gating_id=[0, 0, 0, 0, 0, 2, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0], target_ids=[[21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [6336, 4481, 22014, 6771, 4204, 3], [8732, 3, 0, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [6265, 6672, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [93, 6756, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [15532, 4403, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [6265, 6672, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0]])\n",
    "'''\n",
    "dev_features = processor.convert_examples_to_features(dev_examples)\n",
    "'''dev_features[2]\n",
    "OpenVocabDSTFeature(guid='wild-bonus-5601:식당_택시_12-2', input_id=[2, 3, 11655, 4279, 8553, 18, 6265, 10097, 4073, 8117, 4070, 6259, 4283, 26713, 4403, 4292, 3430, 4219, 3249, 4576, 6216, 18, 3, 11655, 4279, 8553, 18, 8863, 6243, 29365, 4034, 27672, 4034, 13177, 2411, 4114, 4065, 4150, 35, 3, 27672, 4034, 14053, 18781, 4150, 18, 3234, 18, 11139, 4147, 10472, 4110, 6477, 4279, 4034, 2084, 10749, 6465, 8161, 10756, 18, 3, 2279, 18, 3084, 5012, 4576, 6216, 18, 8863, 6265, 16417, 4050, 4073, 6767, 4283, 15119, 4083, 4007, 30524, 2084, 4112, 8538, 4147, 27233, 35, 18790, 4112, 24, 18, 23, 10749, 6465, 4608, 6216, 18, 3, 11946, 4279, 17164, 6479, 3757, 4467, 4172, 6304, 7090, 4151, 4076, 4114, 5012, 7933, 35, 3], segment_id=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], gating_id=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], target_ids=[[21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3]])\n",
    "\n",
    "--> gating_id가 전부 0이고 taret_id가 전부 똑같다(전부 'none'임).\n",
    "\n",
    "dev_labels['wild-bonus-5601:식당_택시_12-2'] = ['식당-가격대-dontcare', '식당-지역-서울 북쪽', '식당-종류-중식당', '식당-주차 가능-yes', '식당-주류 판매-yes']\n",
    "\n",
    "'''\n",
    "print('hoho')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fd1f835-8170-48bf-855a-c9367e62c963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# train: 46287\n",
      "# dev: 4958\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "train_data = WOSDataset(train_features)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_loader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=3,\n",
    "    sampler=train_sampler,\n",
    "    collate_fn=processor.collate_fn,\n",
    ")\n",
    "'''collate_fn에서 한 배치안에서 가장 긴 input_id의 길이를 기준으로 다른 input_id를 패딩한다. \n",
    "'''\n",
    "print(\"# train:\", len(train_data))\n",
    "\n",
    "dev_data = WOSDataset(dev_features)\n",
    "dev_sampler = SequentialSampler(dev_data)\n",
    "dev_loader = DataLoader(\n",
    "    dev_data,\n",
    "    batch_size=3,\n",
    "    sampler=dev_sampler,\n",
    "    collate_fn=processor.collate_fn,\n",
    ")\n",
    "print(\"# dev:\", len(dev_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58323db7-1007-4ae1-a0ad-5db581e78441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is initialized\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import model_transformer\n",
    "import inference\n",
    "importlib.reload(model_transformer)\n",
    "importlib.reload(inference)\n",
    "from inference import inference\n",
    "from model_transformer import TRADE, masked_cross_entropy_for_value\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Model 선언\n",
    "model = TRADE(args, tokenized_slot_meta)\n",
    "# model.set_subword_embedding(args.model_name_or_path)  # Subword Embedding 초기화\n",
    "# print(f\"Subword Embeddings is loaded from {args.model_name_or_path}\")\n",
    "model.to(device)\n",
    "print(\"Model is initialized\")\n",
    "\n",
    "# Optimizer 및 Scheduler 선언\n",
    "n_epochs = args.num_train_epochs\n",
    "t_total = len(train_loader) * n_epochs\n",
    "warmup_steps = int(t_total * args.warmup_ratio)\n",
    "optimizer = AdamW(model.parameters(), lr=args.learning_rate, eps=args.adam_epsilon)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=warmup_steps, num_training_steps=t_total\n",
    ")\n",
    "\n",
    "loss_fnc_1 = masked_cross_entropy_for_value  # generation\n",
    "loss_fnc_2 = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d98e457-55d9-4ef9-976d-a8aad4671e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## reference하는 변수가 없는 오브젝트들을 gpu 메모리에서 free시킨다.\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d309e9a-05e6-4207-8bbf-fd7832d8af77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1140587-eb60-475e-b677-e06a7b07e556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/opt/ml/code/TRADE_transformer_decoder/model_transformer.py\u001b[0m(422)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    420 \u001b[0;31m        \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    421 \u001b[0;31m        \u001b[0;31m# dom_slot자리를 고려하여 causal_mask를 한칸더 크게 만들기 - 했음.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 422 \u001b[0;31m        \u001b[0mtrg_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    423 \u001b[0;31m        \u001b[0mcausal_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_causal_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrg_len\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# shape (trg_len+1, trg_len+1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    424 \u001b[0;31m        \u001b[0;31m## causal_mask는 parallel decoding을 위한 처리를 따로 할 필요없다. 알아서 브로드캐스팅 됨. MultiHeadAttention의 코드 참고.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/opt/ml/code/TRADE_transformer_decoder/model_transformer.py\u001b[0m(423)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    421 \u001b[0;31m        \u001b[0;31m# dom_slot자리를 고려하여 causal_mask를 한칸더 크게 만들기 - 했음.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    422 \u001b[0;31m        \u001b[0mtrg_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 423 \u001b[0;31m        \u001b[0mcausal_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_causal_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrg_len\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# shape (trg_len+1, trg_len+1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    424 \u001b[0;31m        \u001b[0;31m## causal_mask는 parallel decoding을 위한 처리를 따로 할 필요없다. 알아서 브로드캐스팅 됨. MultiHeadAttention의 코드 참고.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    425 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/opt/ml/code/TRADE_transformer_decoder/model_transformer.py\u001b[0m(429)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    427 \u001b[0;31m        \u001b[0;31m#####################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    428 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 429 \u001b[0;31m        \u001b[0minput_masks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mne\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m## input_masks의 True와 False를 반전시킨다.(True는 False로, False는 True로)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    430 \u001b[0;31m        \u001b[0;34m'''transformer 라이브러리의 BERT에서 쓰는 패딩마스크는 [True, True, True, True,True, False, False, False] 와 같은 형태임. 내가 짠 transformer코드에서는 [False, False, False, False, False, True, True, True]같은 형태를 쓰므로 토글시켜줘야 한다.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    431 \u001b[0;31m        \u001b[0;31m# J, slot_meta : key : [domain, slot] ex> LongTensor([1,2])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/opt/ml/code/TRADE_transformer_decoder/model_transformer.py\u001b[0m(434)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    432 \u001b[0;31m        \u001b[0;31m# J,2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    433 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 434 \u001b[0;31m        \u001b[0mslot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslot_embed_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    435 \u001b[0;31m        '''domain-slot을 토크나이징하여 얻은 인덱스들에 패딩까지 넣은것이 slot임\n",
      "\u001b[0m\u001b[0;32m    436 \u001b[0;31m        \u001b[0mshape\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mJ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0m현재\u001b[0m \u001b[0m데이터에서는\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0m가\u001b[0m \u001b[0m토크나이징된\u001b[0m \u001b[0mdomain\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mslot들\u001b[0m \u001b[0m중에\u001b[0m \u001b[0m가장\u001b[0m \u001b[0m긴\u001b[0m \u001b[0m것이다\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/opt/ml/code/TRADE_transformer_decoder/model_transformer.py\u001b[0m(438)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    436 \u001b[0;31m        \u001b[0mshape\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mJ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0m현재\u001b[0m \u001b[0m데이터에서는\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0m가\u001b[0m \u001b[0m토크나이징된\u001b[0m \u001b[0mdomain\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mslot들\u001b[0m \u001b[0m중에\u001b[0m \u001b[0m가장\u001b[0m \u001b[0m긴\u001b[0m \u001b[0m것이다\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    437 \u001b[0;31m        '''\n",
      "\u001b[0m\u001b[0;32m--> 438 \u001b[0;31m        \u001b[0mslot_e\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (J, embedding_dim = 768)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    439 \u001b[0;31m        '''self.embedding(slot).size() = torch.Size([J, slot_length, hidden_size])\n",
      "\u001b[0m\u001b[0;32m    440 \u001b[0;31m        \u001b[0m한\u001b[0m \u001b[0mdomain\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mslot에\u001b[0m \u001b[0m대한\u001b[0m \u001b[0m모든\u001b[0m \u001b[0m토큰들의\u001b[0m \u001b[0m임베딩벡터를\u001b[0m \u001b[0m합친다\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mJ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/opt/ml/code/TRADE_transformer_decoder/model_transformer.py\u001b[0m(443)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    441 \u001b[0;31m        \u001b[0;34m-\u001b[0m\u001b[0;34m->\u001b[0m \u001b[0mslot_e\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0m은\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0m번째\u001b[0m \u001b[0mslot의\u001b[0m \u001b[0membedding\u001b[0m \u001b[0mvector인\u001b[0m \u001b[0m것임\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    442 \u001b[0;31m        '''\n",
      "\u001b[0m\u001b[0;32m--> 443 \u001b[0;31m        \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    444 \u001b[0;31m        \u001b[0mJ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslot_e\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    445 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/opt/ml/code/TRADE_transformer_decoder/model_transformer.py\u001b[0m(444)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    442 \u001b[0;31m        '''\n",
      "\u001b[0m\u001b[0;32m    443 \u001b[0;31m        \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 444 \u001b[0;31m        \u001b[0mJ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslot_e\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    445 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    446 \u001b[0;31m        \u001b[0;31m##inputs_embed에 dom_slot에 대한 embeding vecotor를 맨 앞에 넣어준다.(J*batch_size, trg_len+1, hidden_size)로 만들어야 함.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/opt/ml/code/TRADE_transformer_decoder/model_transformer.py\u001b[0m(447)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    445 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    446 \u001b[0;31m        \u001b[0;31m##inputs_embed에 dom_slot에 대한 embeding vecotor를 맨 앞에 넣어준다.(J*batch_size, trg_len+1, hidden_size)로 만들어야 함.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 447 \u001b[0;31m        \u001b[0mdecoder_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mJ\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg_len\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (J*batch_size, trg_len+1, hidden_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    448 \u001b[0;31m        \u001b[0mslot_e\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslot_e\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (J*batch_size, hidden_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    449 \u001b[0;31m        \u001b[0mtarget_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mJ\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m## (J*batch_size, trg_len)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/opt/ml/code/TRADE_transformer_decoder/model_transformer.py\u001b[0m(448)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    446 \u001b[0;31m        \u001b[0;31m##inputs_embed에 dom_slot에 대한 embeding vecotor를 맨 앞에 넣어준다.(J*batch_size, trg_len+1, hidden_size)로 만들어야 함.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    447 \u001b[0;31m        \u001b[0mdecoder_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mJ\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg_len\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (J*batch_size, trg_len+1, hidden_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 448 \u001b[0;31m        \u001b[0mslot_e\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslot_e\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (J*batch_size, hidden_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    449 \u001b[0;31m        \u001b[0mtarget_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mJ\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m## (J*batch_size, trg_len)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    450 \u001b[0;31m        \u001b[0mtargets_embed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m## (J*batch_size, trg_len, hidden_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/opt/ml/code/TRADE_transformer_decoder/model_transformer.py\u001b[0m(449)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    447 \u001b[0;31m        \u001b[0mdecoder_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mJ\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg_len\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (J*batch_size, trg_len+1, hidden_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    448 \u001b[0;31m        \u001b[0mslot_e\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslot_e\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (J*batch_size, hidden_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 449 \u001b[0;31m        \u001b[0mtarget_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mJ\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m## (J*batch_size, trg_len)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    450 \u001b[0;31m        \u001b[0mtargets_embed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m## (J*batch_size, trg_len, hidden_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    451 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  target_ids\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [ 9459,     3,     0,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [   93,  6756,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [ 6265,  9778,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0]],\n",
      "\n",
      "        [[21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [ 8784,     3,     0,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [18101,     3,     0,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [33922,  4019, 21172,  7139,     3],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [   93,  6756,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0]],\n",
      "\n",
      "        [[21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [10238,     3,     0,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [   21,     3,     0,     0,     0],\n",
      "         [   25,     3,     0,     0,     0],\n",
      "         [11711,     3,     0,     0,     0],\n",
      "         [28486,  7396,  6265,     3,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [ 7396,     3,     0,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [ 6265,  6672,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [33922,  4019, 21172,  7139,     3],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [   25,     3,     0,     0,     0],\n",
      "         [10773,    30,  6526,     3,     0],\n",
      "         [11711,     3,     0,     0,     0],\n",
      "         [19868,  4234,  4641,  4557,     3],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [15532,  4403,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [ 6265,  6672,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [21832, 11764,     3,     0,     0],\n",
      "         [28486,  7396,  6265,     3,     0],\n",
      "         [33922,  4019, 21172,  7139,     3],\n",
      "         [ 9396,    30,  7473,     3,     0],\n",
      "         [19868,  4234,  4641,  4557,     3]]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/opt/ml/code/TRADE_transformer_decoder/model_transformer.py\u001b[0m(450)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    448 \u001b[0;31m        \u001b[0mslot_e\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslot_e\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (J*batch_size, hidden_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    449 \u001b[0;31m        \u001b[0mtarget_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mJ\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m## (J*batch_size, trg_len)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 450 \u001b[0;31m        \u001b[0mtargets_embed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m## (J*batch_size, trg_len, hidden_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    451 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    452 \u001b[0;31m        \u001b[0mdecoder_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets_embed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  target_ids\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [ 9459,     3,     0,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [   93,  6756,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [ 6265,  9778,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [ 8784,     3,     0,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [18101,     3,     0,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [33922,  4019, 21172,  7139,     3],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [   93,  6756,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [10238,     3,     0,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [   21,     3,     0,     0,     0],\n",
      "        [   25,     3,     0,     0,     0],\n",
      "        [11711,     3,     0,     0,     0],\n",
      "        [28486,  7396,  6265,     3,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [ 7396,     3,     0,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [ 6265,  6672,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [33922,  4019, 21172,  7139,     3],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [   25,     3,     0,     0,     0],\n",
      "        [10773,    30,  6526,     3,     0],\n",
      "        [11711,     3,     0,     0,     0],\n",
      "        [19868,  4234,  4641,  4557,     3],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [15532,  4403,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [ 6265,  6672,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [21832, 11764,     3,     0,     0],\n",
      "        [28486,  7396,  6265,     3,     0],\n",
      "        [33922,  4019, 21172,  7139,     3],\n",
      "        [ 9396,    30,  7473,     3,     0],\n",
      "        [19868,  4234,  4641,  4557,     3]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/opt/ml/code/TRADE_transformer_decoder/model_transformer.py\u001b[0m(452)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    450 \u001b[0;31m        \u001b[0mtargets_embed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m## (J*batch_size, trg_len, hidden_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    451 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 452 \u001b[0;31m        \u001b[0mdecoder_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets_embed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    453 \u001b[0;31m        \u001b[0mdecoder_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslot_e\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    454 \u001b[0;31m        '''첫번째 데이터에 대한 slot1 의 value벡터(trg_len+1, hidden_size)가 나오고 그다음\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/opt/ml/code/TRADE_transformer_decoder/model_transformer.py\u001b[0m(453)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    451 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    452 \u001b[0;31m        \u001b[0mdecoder_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets_embed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 453 \u001b[0;31m        \u001b[0mdecoder_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslot_e\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    454 \u001b[0;31m        '''첫번째 데이터에 대한 slot1 의 value벡터(trg_len+1, hidden_size)가 나오고 그다음\n",
      "\u001b[0m\u001b[0;32m    455 \u001b[0;31m        \u001b[0m첫번째\u001b[0m \u001b[0m데이터에\u001b[0m \u001b[0m대한\u001b[0m \u001b[0mslot2의\u001b[0m \u001b[0mvalue벡터\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrg_len\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0m가\u001b[0m \u001b[0m나오고\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/opt/ml/code/TRADE_transformer_decoder/model_transformer.py\u001b[0m(462)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    460 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    461 \u001b[0;31m        \u001b[0;31m##dom_slot을 고려하여 한칸 만큼 더 큰 pos_embed를 만든다. -> 했음.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 462 \u001b[0;31m        \u001b[0mpos_embed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_positions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m## (J*batch_size, trg_len+1, hidden_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    463 \u001b[0;31m        \u001b[0mdecoder_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_input\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpos_embed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    464 \u001b[0;31m        \u001b[0mdecoder_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_drop_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  decoder_input[:,0,:3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0447, -0.1087, -0.0159],\n",
      "        [-0.0150, -0.0414, -0.0780],\n",
      "        [ 0.1801,  0.0679, -0.0746],\n",
      "        [ 0.1522, -0.0320,  0.0410],\n",
      "        [ 0.0706,  0.0852, -0.1165],\n",
      "        [ 0.1603,  0.1618, -0.1339],\n",
      "        [ 0.1611,  0.0808, -0.0767],\n",
      "        [ 0.1622,  0.0553, -0.1443],\n",
      "        [ 0.2025,  0.0596, -0.1153],\n",
      "        [ 0.1520,  0.1092, -0.1678],\n",
      "        [ 0.1547,  0.1440, -0.1313],\n",
      "        [ 0.1407, -0.0244, -0.2119],\n",
      "        [ 0.1015, -0.0085, -0.1874],\n",
      "        [ 0.1322, -0.0368, -0.1185],\n",
      "        [ 0.1528,  0.0038, -0.0061],\n",
      "        [ 0.0697,  0.0268, -0.0932],\n",
      "        [ 0.1349,  0.2378, -0.1905],\n",
      "        [ 0.1374,  0.2059, -0.0642],\n",
      "        [ 0.1769,  0.2451, -0.1319],\n",
      "        [ 0.1357,  0.1568, -0.1334],\n",
      "        [ 0.1368,  0.1313, -0.2010],\n",
      "        [ 0.1772,  0.1356, -0.1720],\n",
      "        [ 0.1460, -0.0657,  0.0242],\n",
      "        [ 0.1880,  0.2472, -0.1353],\n",
      "        [ 0.1605,  0.0937, -0.1446],\n",
      "        [ 0.1631,  0.1285, -0.1081],\n",
      "        [ 0.0675, -0.1390, -0.0153],\n",
      "        [ 0.1612, -0.0117,  0.0171],\n",
      "        [ 0.1654,  0.0048, -0.1030],\n",
      "        [ 0.0781,  0.0113, -0.0700],\n",
      "        [ 0.1434,  0.2223, -0.1674],\n",
      "        [ 0.1458,  0.1904, -0.0410],\n",
      "        [ 0.1441,  0.1414, -0.1102],\n",
      "        [ 0.1677,  0.1134, -0.0057],\n",
      "        [ 0.1452,  0.1158, -0.1778],\n",
      "        [ 0.1856,  0.1201, -0.1488],\n",
      "        [ 0.1964,  0.2317, -0.1121],\n",
      "        [ 0.2068,  0.1974, -0.1145],\n",
      "        [ 0.0728, -0.0245, -0.1388],\n",
      "        [ 0.2200,  0.1328, -0.0439],\n",
      "        [ 0.0573,  0.0424, -0.1591],\n",
      "        [ 0.2045,  0.1997, -0.0642],\n",
      "        [ 0.1048,  0.0807, -0.1050],\n",
      "        [ 0.0706, -0.0222, -0.0885],\n",
      "        [ 0.2178,  0.1351,  0.0064],\n",
      "        [-0.0447, -0.1087, -0.0159],\n",
      "        [-0.0150, -0.0414, -0.0780],\n",
      "        [ 0.1801,  0.0679, -0.0746],\n",
      "        [ 0.1522, -0.0320,  0.0410],\n",
      "        [ 0.0706,  0.0852, -0.1165],\n",
      "        [ 0.1603,  0.1618, -0.1339],\n",
      "        [ 0.1611,  0.0808, -0.0767],\n",
      "        [ 0.1622,  0.0553, -0.1443],\n",
      "        [ 0.2025,  0.0596, -0.1153],\n",
      "        [ 0.1520,  0.1092, -0.1678],\n",
      "        [ 0.1547,  0.1440, -0.1313],\n",
      "        [ 0.1407, -0.0244, -0.2119],\n",
      "        [ 0.1015, -0.0085, -0.1874],\n",
      "        [ 0.1322, -0.0368, -0.1185],\n",
      "        [ 0.1528,  0.0038, -0.0061],\n",
      "        [ 0.0697,  0.0268, -0.0932],\n",
      "        [ 0.1349,  0.2378, -0.1905],\n",
      "        [ 0.1374,  0.2059, -0.0642],\n",
      "        [ 0.1769,  0.2451, -0.1319],\n",
      "        [ 0.1357,  0.1568, -0.1334],\n",
      "        [ 0.1368,  0.1313, -0.2010],\n",
      "        [ 0.1772,  0.1356, -0.1720],\n",
      "        [ 0.1460, -0.0657,  0.0242],\n",
      "        [ 0.1880,  0.2472, -0.1353],\n",
      "        [ 0.1605,  0.0937, -0.1446],\n",
      "        [ 0.1631,  0.1285, -0.1081],\n",
      "        [ 0.0675, -0.1390, -0.0153],\n",
      "        [ 0.1612, -0.0117,  0.0171],\n",
      "        [ 0.1654,  0.0048, -0.1030],\n",
      "        [ 0.0781,  0.0113, -0.0700],\n",
      "        [ 0.1434,  0.2223, -0.1674],\n",
      "        [ 0.1458,  0.1904, -0.0410],\n",
      "        [ 0.1441,  0.1414, -0.1102],\n",
      "        [ 0.1677,  0.1134, -0.0057],\n",
      "        [ 0.1452,  0.1158, -0.1778],\n",
      "        [ 0.1856,  0.1201, -0.1488],\n",
      "        [ 0.1964,  0.2317, -0.1121],\n",
      "        [ 0.2068,  0.1974, -0.1145],\n",
      "        [ 0.0728, -0.0245, -0.1388],\n",
      "        [ 0.2200,  0.1328, -0.0439],\n",
      "        [ 0.0573,  0.0424, -0.1591],\n",
      "        [ 0.2045,  0.1997, -0.0642],\n",
      "        [ 0.1048,  0.0807, -0.1050],\n",
      "        [ 0.0706, -0.0222, -0.0885],\n",
      "        [ 0.2178,  0.1351,  0.0064],\n",
      "        [-0.0447, -0.1087, -0.0159],\n",
      "        [-0.0150, -0.0414, -0.0780],\n",
      "        [ 0.1801,  0.0679, -0.0746],\n",
      "        [ 0.1522, -0.0320,  0.0410],\n",
      "        [ 0.0706,  0.0852, -0.1165],\n",
      "        [ 0.1603,  0.1618, -0.1339],\n",
      "        [ 0.1611,  0.0808, -0.0767],\n",
      "        [ 0.1622,  0.0553, -0.1443],\n",
      "        [ 0.2025,  0.0596, -0.1153],\n",
      "        [ 0.1520,  0.1092, -0.1678],\n",
      "        [ 0.1547,  0.1440, -0.1313],\n",
      "        [ 0.1407, -0.0244, -0.2119],\n",
      "        [ 0.1015, -0.0085, -0.1874],\n",
      "        [ 0.1322, -0.0368, -0.1185],\n",
      "        [ 0.1528,  0.0038, -0.0061],\n",
      "        [ 0.0697,  0.0268, -0.0932],\n",
      "        [ 0.1349,  0.2378, -0.1905],\n",
      "        [ 0.1374,  0.2059, -0.0642],\n",
      "        [ 0.1769,  0.2451, -0.1319],\n",
      "        [ 0.1357,  0.1568, -0.1334],\n",
      "        [ 0.1368,  0.1313, -0.2010],\n",
      "        [ 0.1772,  0.1356, -0.1720],\n",
      "        [ 0.1460, -0.0657,  0.0242],\n",
      "        [ 0.1880,  0.2472, -0.1353],\n",
      "        [ 0.1605,  0.0937, -0.1446],\n",
      "        [ 0.1631,  0.1285, -0.1081],\n",
      "        [ 0.0675, -0.1390, -0.0153],\n",
      "        [ 0.1612, -0.0117,  0.0171],\n",
      "        [ 0.1654,  0.0048, -0.1030],\n",
      "        [ 0.0781,  0.0113, -0.0700],\n",
      "        [ 0.1434,  0.2223, -0.1674],\n",
      "        [ 0.1458,  0.1904, -0.0410],\n",
      "        [ 0.1441,  0.1414, -0.1102],\n",
      "        [ 0.1677,  0.1134, -0.0057],\n",
      "        [ 0.1452,  0.1158, -0.1778],\n",
      "        [ 0.1856,  0.1201, -0.1488],\n",
      "        [ 0.1964,  0.2317, -0.1121],\n",
      "        [ 0.2068,  0.1974, -0.1145],\n",
      "        [ 0.0728, -0.0245, -0.1388],\n",
      "        [ 0.2200,  0.1328, -0.0439],\n",
      "        [ 0.0573,  0.0424, -0.1591],\n",
      "        [ 0.2045,  0.1997, -0.0642],\n",
      "        [ 0.1048,  0.0807, -0.1050],\n",
      "        [ 0.0706, -0.0222, -0.0885],\n",
      "        [ 0.2178,  0.1351,  0.0064]], device='cuda:0', grad_fn=<SliceBackward>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  decoder_input[0,:,0:3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0447, -0.1087, -0.0159],\n",
      "        [-0.0521,  0.0296,  0.0271],\n",
      "        [ 0.0053, -0.0106,  0.0190],\n",
      "        [-0.0117, -0.0335,  0.0225],\n",
      "        [ 0.0405,  0.0565, -0.0827],\n",
      "        [ 0.0405,  0.0565, -0.0827]], device='cuda:0', grad_fn=<SliceBackward>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  decoder_input[1,:,0:3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0150, -0.0414, -0.0780],\n",
      "        [-0.0521,  0.0296,  0.0271],\n",
      "        [ 0.0053, -0.0106,  0.0190],\n",
      "        [-0.0117, -0.0335,  0.0225],\n",
      "        [ 0.0405,  0.0565, -0.0827],\n",
      "        [ 0.0405,  0.0565, -0.0827]], device='cuda:0', grad_fn=<SliceBackward>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  targets_embed[0,:,0:3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0521,  0.0296,  0.0271],\n",
      "        [ 0.0053, -0.0106,  0.0190],\n",
      "        [-0.0117, -0.0335,  0.0225],\n",
      "        [ 0.0405,  0.0565, -0.0827],\n",
      "        [ 0.0405,  0.0565, -0.0827]], device='cuda:0', grad_fn=<SliceBackward>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  targets_embed[9,:,0:3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0227, -0.0157, -0.0697],\n",
      "        [-0.0117, -0.0335,  0.0225],\n",
      "        [ 0.0405,  0.0565, -0.0827],\n",
      "        [ 0.0405,  0.0565, -0.0827],\n",
      "        [ 0.0405,  0.0565, -0.0827]], device='cuda:0', grad_fn=<SliceBackward>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  decoder_input[9,:,0:3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1520,  0.1092, -0.1678],\n",
      "        [ 0.0227, -0.0157, -0.0697],\n",
      "        [-0.0117, -0.0335,  0.0225],\n",
      "        [ 0.0405,  0.0565, -0.0827],\n",
      "        [ 0.0405,  0.0565, -0.0827],\n",
      "        [ 0.0405,  0.0565, -0.0827]], device='cuda:0', grad_fn=<SliceBackward>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  slot_e[9,:3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1520,  0.1092, -0.1678], device='cuda:0', grad_fn=<SliceBackward>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  decoder_input[9+45,:,0:3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1520,  0.1092, -0.1678],\n",
      "        [-0.0691,  0.0293, -0.0100],\n",
      "        [-0.0117, -0.0335,  0.0225],\n",
      "        [ 0.0405,  0.0565, -0.0827],\n",
      "        [ 0.0405,  0.0565, -0.0827],\n",
      "        [ 0.0405,  0.0565, -0.0827]], device='cuda:0', grad_fn=<SliceBackward>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/opt/ml/code/TRADE_transformer_decoder/model_transformer.py\u001b[0m(463)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    461 \u001b[0;31m        \u001b[0;31m##dom_slot을 고려하여 한칸 만큼 더 큰 pos_embed를 만든다. -> 했음.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    462 \u001b[0;31m        \u001b[0mpos_embed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_positions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m## (J*batch_size, trg_len+1, hidden_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 463 \u001b[0;31m        \u001b[0mdecoder_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_input\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpos_embed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    464 \u001b[0;31m        \u001b[0mdecoder_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_drop_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    465 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  pos_enbed[:,:,0:3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** NameError: name 'pos_enbed' is not defined\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  pos_embed[:,:,0:3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** IndexError: too many indices for tensor of dimension 2\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  target_ids.size()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([135, 5])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  positions.size()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** NameError: name 'positions' is not defined\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  pos_embed.size()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 768])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  pos_embed[:,:3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000,  1.0000,  0.0000],\n",
      "        [ 0.8415,  0.5403,  0.8284],\n",
      "        [ 0.9093, -0.4161,  0.9280],\n",
      "        [ 0.1411, -0.9900,  0.2111],\n",
      "        [-0.7568, -0.6536, -0.6915],\n",
      "        [-0.9589,  0.2837, -0.9857]], device='cuda:0', grad_fn=<SliceBackward>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  decoder_input[0,:,:3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0447, -0.1087, -0.0159],\n",
      "        [-0.0521,  0.0296,  0.0271],\n",
      "        [ 0.0053, -0.0106,  0.0190],\n",
      "        [-0.0117, -0.0335,  0.0225],\n",
      "        [ 0.0405,  0.0565, -0.0827],\n",
      "        [ 0.0405,  0.0565, -0.0827]], device='cuda:0', grad_fn=<SliceBackward>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  decoder_input[1,:,:3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0150, -0.0414, -0.0780],\n",
      "        [-0.0521,  0.0296,  0.0271],\n",
      "        [ 0.0053, -0.0106,  0.0190],\n",
      "        [-0.0117, -0.0335,  0.0225],\n",
      "        [ 0.0405,  0.0565, -0.0827],\n",
      "        [ 0.0405,  0.0565, -0.0827]], device='cuda:0', grad_fn=<SliceBackward>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/opt/ml/code/TRADE_transformer_decoder/model_transformer.py\u001b[0m(464)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    462 \u001b[0;31m        \u001b[0mpos_embed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_positions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m## (J*batch_size, trg_len+1, hidden_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    463 \u001b[0;31m        \u001b[0mdecoder_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_input\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpos_embed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 464 \u001b[0;31m        \u001b[0mdecoder_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_drop_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    465 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    466 \u001b[0;31m        \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat_interleave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mJ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  decoder_input[0,:,:3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0447,  0.8913, -0.0159],\n",
      "        [ 0.7894,  0.5699,  0.8555],\n",
      "        [ 0.9146, -0.4268,  0.9470],\n",
      "        [ 0.1294, -1.0235,  0.2336],\n",
      "        [-0.7163, -0.5971, -0.7742],\n",
      "        [-0.9184,  0.3402, -1.0684]], device='cuda:0', grad_fn=<SliceBackward>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  decoder_input[1,:,:3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0150,  0.9586, -0.0780],\n",
      "        [ 0.7894,  0.5699,  0.8555],\n",
      "        [ 0.9146, -0.4268,  0.9470],\n",
      "        [ 0.1294, -1.0235,  0.2336],\n",
      "        [-0.7163, -0.5971, -0.7742],\n",
      "        [-0.9184,  0.3402, -1.0684]], device='cuda:0', grad_fn=<SliceBackward>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/opt/ml/code/TRADE_transformer_decoder/model_transformer.py\u001b[0m(466)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    464 \u001b[0;31m        \u001b[0mdecoder_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_drop_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    465 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 466 \u001b[0;31m        \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat_interleave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mJ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    467 \u001b[0;31m        '''(J*batch_size, src_len)\n",
      "\u001b[0m\u001b[0;32m    468 \u001b[0;31m        \u001b[0m첫번째\u001b[0m \u001b[0m데이터에\u001b[0m \u001b[0m대한\u001b[0m \u001b[0minput_id가\u001b[0m \u001b[0mJ번\u001b[0m \u001b[0m반복되고\u001b[0m \u001b[0m두번째\u001b[0m \u001b[0m데이터에\u001b[0m \u001b[0m대한\u001b[0m \u001b[0minput_id가\u001b[0m \u001b[0mJ번\u001b[0m \u001b[0m반복되고\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/opt/ml/code/TRADE_transformer_decoder/model_transformer.py\u001b[0m(471)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    469 \u001b[0;31m        '''        \n",
      "\u001b[0m\u001b[0;32m    470 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 471 \u001b[0;31m        \u001b[0minput_masks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat_interleave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mJ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    472 \u001b[0;31m        '''(J*batch_size, seq_len)\n",
      "\u001b[0m\u001b[0;32m    473 \u001b[0;31m        첫번째 데이터에 대한 input_mask가 J번 반복되고 두번째 데이터에 대한 input_mask가 J번 반복되고 ...'''\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  input_ids[:,:3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3,  8408],\n",
      "        [    2,     3,  8408],\n",
      "        [    2,     3,  8408],\n",
      "        [    2,     3,  8408],\n",
      "        [    2,     3,  8408],\n",
      "        [    2,     3,  8408],\n",
      "        [    2,     3,  8408],\n",
      "        [    2,     3,  8408],\n",
      "        [    2,     3,  8408],\n",
      "        [    2,     3,  8408],\n",
      "        [    2,     3,  8408],\n",
      "        [    2,     3,  8408],\n",
      "        [    2,     3,  8408],\n",
      "        [    2,     3,  8408],\n",
      "        [    2,     3,  8408],\n",
      "        [    2,     3,  8408],\n",
      "        [    2,     3,  8408],\n",
      "        [    2,     3,  8408],\n",
      "        [    2,     3,  8408],\n",
      "        [    2,     3,  8408],\n",
      "        [    2,     3,  8408],\n",
      "        [    2,     3,  8408],\n",
      "        [    2,     3,  8408],\n",
      "        [    2,     3,  8408],\n",
      "        [    2,     3,  8408],\n",
      "        [    2,     3,  8408],\n",
      "        [    2,     3,  8408],\n",
      "        [    2,     3,  8408],\n",
      "        [    2,     3,  8408],\n",
      "        [    2,     3,  8408],\n",
      "        [    2,     3,  8408],\n",
      "        [    2,     3,  8408],\n",
      "        [    2,     3,  8408],\n",
      "        [    2,     3,  8408],\n",
      "        [    2,     3,  8408],\n",
      "        [    2,     3,  8408],\n",
      "        [    2,     3,  8408],\n",
      "        [    2,     3,  8408],\n",
      "        [    2,     3,  8408],\n",
      "        [    2,     3,  8408],\n",
      "        [    2,     3,  8408],\n",
      "        [    2,     3,  8408],\n",
      "        [    2,     3,  8408],\n",
      "        [    2,     3,  8408],\n",
      "        [    2,     3,  8408],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655],\n",
      "        [    2,     3, 11655]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  input_ids.size()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([135, 446])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/opt/ml/code/TRADE_transformer_decoder/model_transformer.py\u001b[0m(474)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    472 \u001b[0;31m        '''(J*batch_size, seq_len)\n",
      "\u001b[0m\u001b[0;32m    473 \u001b[0;31m        첫번째 데이터에 대한 input_mask가 J번 반복되고 두번째 데이터에 대한 input_mask가 J번 반복되고 ...'''\n",
      "\u001b[0m\u001b[0;32m--> 474 \u001b[0;31m        \u001b[0mencoder_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat_interleave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mJ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    475 \u001b[0;31m        '''(J*batch_size, src_len, hidden_size)첫번째 데이터에 대한 (1, src_len, hidden_size)가 J번 반복되고 \n",
      "\u001b[0m\u001b[0;32m    476 \u001b[0;31m        \u001b[0m그\u001b[0m \u001b[0m다음\u001b[0m \u001b[0m두번째\u001b[0m \u001b[0m데이터에\u001b[0m \u001b[0m대한\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0m가\u001b[0m \u001b[0mJ번\u001b[0m \u001b[0m반복되고\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/opt/ml/code/TRADE_transformer_decoder/model_transformer.py\u001b[0m(479)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    477 \u001b[0;31m        '''\n",
      "\u001b[0m\u001b[0;32m    478 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 479 \u001b[0;31m        \u001b[0menc_dec_attn_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    480 \u001b[0;31m        \u001b[0;32mfor\u001b[0m \u001b[0mdecoder_layer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    481 \u001b[0;31m            decoder_input, _, attn_weights = decoder_layer(decoder_input, \n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  target_embed[:,:,:3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** NameError: name 'target_embed' is not defined\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  targets_embed[:,:,:3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0521,  0.0296,  0.0271],\n",
      "         [ 0.0053, -0.0106,  0.0190],\n",
      "         [-0.0117, -0.0335,  0.0225],\n",
      "         [ 0.0405,  0.0565, -0.0827],\n",
      "         [ 0.0405,  0.0565, -0.0827]],\n",
      "\n",
      "        [[-0.0521,  0.0296,  0.0271],\n",
      "         [ 0.0053, -0.0106,  0.0190],\n",
      "         [-0.0117, -0.0335,  0.0225],\n",
      "         [ 0.0405,  0.0565, -0.0827],\n",
      "         [ 0.0405,  0.0565, -0.0827]],\n",
      "\n",
      "        [[-0.0521,  0.0296,  0.0271],\n",
      "         [ 0.0053, -0.0106,  0.0190],\n",
      "         [-0.0117, -0.0335,  0.0225],\n",
      "         [ 0.0405,  0.0565, -0.0827],\n",
      "         [ 0.0405,  0.0565, -0.0827]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0534,  0.0643,  0.0315],\n",
      "         [ 0.1325,  0.0267, -0.0237],\n",
      "         [-0.0600, -0.0250,  0.0295],\n",
      "         [ 0.0294, -0.0456, -0.0897],\n",
      "         [-0.0117, -0.0335,  0.0225]],\n",
      "\n",
      "        [[-0.0066,  0.0227, -0.0155],\n",
      "         [-0.0577,  0.0336, -0.0785],\n",
      "         [ 0.0541,  0.0101,  0.0498],\n",
      "         [-0.0117, -0.0335,  0.0225],\n",
      "         [ 0.0405,  0.0565, -0.0827]],\n",
      "\n",
      "        [[ 0.0866, -0.0871,  0.0183],\n",
      "         [ 0.0124, -0.0333,  0.0048],\n",
      "         [-0.0604,  0.0298,  0.0552],\n",
      "         [-0.0513,  0.0179,  0.1009],\n",
      "         [-0.0117, -0.0335,  0.0225]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "best_score, best_checkpoint = 0, 0\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    for step, batch in enumerate(train_loader):\n",
    "        input_ids, segment_ids, input_masks, gating_ids, target_ids, guids = [\n",
    "            b.to(device) if not isinstance(b, list) else b for b in batch\n",
    "        ] ## b가 list가 아니면 b.to(device)를 하고 b가 list면 그냥 b를 쓴다.\n",
    "\n",
    "        all_point_outputs, all_gate_outputs = model(\n",
    "            input_ids, target_ids, segment_ids, input_masks, \n",
    "        )\n",
    "        pdb.set_trace()\n",
    "\n",
    "        # generation loss\n",
    "        loss_1 = loss_fnc_1(\n",
    "            all_point_outputs.contiguous(),\n",
    "            target_ids.contiguous().view(-1),\n",
    "            tokenizer.pad_token_id,\n",
    "        )\n",
    "\n",
    "        # gating loss\n",
    "        loss_2 = loss_fnc_2(\n",
    "            all_gate_outputs.contiguous().view(-1, args.n_gate),\n",
    "            gating_ids.contiguous().view(-1),\n",
    "        )\n",
    "        loss = loss_1 + loss_2\n",
    "\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predictions = inference(model, dev_loader, processor, device)\n",
    "        eval_result = _evaluation(predictions, dev_labels, slot_meta)\n",
    "        torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
