{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6aedecbf-5440-4dc4-9e3c-fc51cfbafa16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "\n",
    "import easydict\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from tqdm import tqdm\n",
    "from transformers import AdamW, BertTokenizer, get_linear_schedule_with_warmup\n",
    "\n",
    "from data_utils import (WOSDataset, get_examples_from_dialogues, load_dataset, set_seed,\n",
    "                        seed_everything)\n",
    "from eval_utils import DSTEvaluator\n",
    "from evaluation import _evaluation\n",
    "from inference import inference\n",
    "from preprocessor import TRADEPreprocessor\n",
    "# from my_transformer import Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e68b5314-df68-4d3b-9117-d6cf165038f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = easydict.EasyDict({\n",
    "    'data_dir' : \"../../input/data/train_dataset\",\n",
    "    'model_dir' : \"results\",\n",
    "    'train_batch_size' : 4,\n",
    "    'eval_batch_size' : 32,\n",
    "    'learning_rate' : 1e-4,\n",
    "    'adam_epsilon' : 1e-8,\n",
    "    'max_grad_norm' : 1.0,\n",
    "    'num_train_epochs' : 30,\n",
    "    'warmup_ratio' : 0.1,\n",
    "    'random_seed' : 42,\n",
    "    'model_name_or_path' : 'dsksd/bert-ko-small-minimal',\n",
    "    'hidden_size' : 768,\n",
    "    'vocab_size' : None,\n",
    "    'hidden_dropout_prob' : 0.1,\n",
    "    'proj_dim' : None,\n",
    "    'teacher_forcing_ratio' : 0.5,\n",
    "    'word_dropout' : 0,\n",
    "    'max_position' : 512,\n",
    "    'attention_drop_out' : 0.1,\n",
    "    'num_attention_heads' : 6,\n",
    "    'ffn_dim' : 768*2,\n",
    "    'num_decoder_layers' : 6\n",
    "    \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b6d1eda-6dc4-4472-8f7e-118e3c7125a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6301/6301 [00:00<00:00, 11049.86it/s]\n",
      "100%|██████████| 699/699 [00:00<00:00, 2790.57it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\ndev_examples[10] = DSTInputExample(guid='shy-sea-4716:관광_11-2', context_turns=['', '제가 서울을 처음 와봐서 문화 예술과 관련된 곳으로 관광하고 싶은데 어디로 가면 될까요?', '안녕하세요. 관광을 원하시는 지역과 종류가 있으시면 말씀해주세요.', '서울 중앙쪽으로 알려주세요. 종류는 글쎄요 잘 모르겠어요.'], current_turn=['네. 그럼 명동난타극장과 삼성미술관 라움, 정동극장을 추천해드립니다. 어디가 괜찮으세요?', '미술관이 좋을것 같아요. 지하철로 이동하려고 하는데 어디에서 내리면 되나요?'], label=None)\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_file = f\"{args.data_dir}/train_dials.json\"\n",
    "slot_meta = json.load(open(f\"{args.data_dir}/slot_meta.json\"))\n",
    "'''['관광-경치 좋은', '관광-교육적', '관광-도보 가능', '관광-문화 예술', '관광-역사적', '관광-이름', '관광-종류', '관광-주차 가능', '관광-지역', '숙소-가격대', '숙소-도보 가능', '숙소-수영장 유무', '숙소-스파 유무', '숙소-예약 기간', '숙소-예약 명수', '숙소-예약 요일', '숙소-이름', '숙소-인터넷 가능', '숙소-조식 가능', '숙소-종류', '숙소-주차 가능', '숙소-지역', '숙소-헬스장 유무', '숙소-흡연 가능', '식당-가격대', '식당-도보 가능', '식당-야외석 유무', '식당-예약 명수', '식당-예약 시간', '식당-예약 요일', '식당-이름', '식당-인터넷 가능', '식당-종류', '식당-주류 판매', '식당-주차 가능', '식당-지역', '식당-흡연 가능', '지하철-도착지', '지하철-출발 시간', '지하철-출발지', '택시-도착 시간', '택시-도착지', '택시-종류', '택시-출발 시간', '택시-출발지']'''\n",
    "train_data, dev_data, dev_labels = load_dataset(train_data_file)\n",
    "\n",
    "train_examples = get_examples_from_dialogues(\n",
    "    train_data, user_first=False, dialogue_level=False\n",
    ")\n",
    "'''\n",
    "train_examples[10] = DSTInputExample(guid='polished-poetry-0057:관광_9-2', context_turns=['', '쇼핑을 하려는데 서울 서쪽에 있을까요?', '서울 서쪽에 쇼핑이 가능한 곳이라면 노량진 수산물 도매시장이 있습니다.', '오 네 거기 주소 좀 알려주세요.'], current_turn=['노량진 수산물 도매시장의 주소는 서울 동작구 93806입니다.', '알려주시는김에 연락처랑 평점도 좀 알려주세요.'], label=['관광-종류-쇼핑', '관광-지역-서울 서쪽', '관광-이름-노량진 수산물 도매시장'])\n",
    "'''\n",
    "dev_examples = get_examples_from_dialogues(\n",
    "    dev_data, user_first=False, dialogue_level=False\n",
    ")\n",
    "'''\n",
    "dev_examples[10] = DSTInputExample(guid='shy-sea-4716:관광_11-2', context_turns=['', '제가 서울을 처음 와봐서 문화 예술과 관련된 곳으로 관광하고 싶은데 어디로 가면 될까요?', '안녕하세요. 관광을 원하시는 지역과 종류가 있으시면 말씀해주세요.', '서울 중앙쪽으로 알려주세요. 종류는 글쎄요 잘 모르겠어요.'], current_turn=['네. 그럼 명동난타극장과 삼성미술관 라움, 정동극장을 추천해드립니다. 어디가 괜찮으세요?', '미술관이 좋을것 같아요. 지하철로 이동하려고 하는데 어디에서 내리면 되나요?'], label=None)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4690d69-c0f7-4cc0-8d5a-d8ddb490f82a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'각 domain-slot pair를 토크나이징 한다.\\ntokenized_slot_meta[0] = [6728, 21170, 3311, 4112]\\ntokenized_slot_meta[1] = [6728, 6295, 4199, 0]\\ntokenized_slot_meta[2] = [6728, 17502, 6259, 0]\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define Preprocessor\n",
    "tokenizer = BertTokenizer.from_pretrained(args.model_name_or_path)\n",
    "processor = TRADEPreprocessor(slot_meta, tokenizer, word_dropout_rate = args.word_dropout)\n",
    "args.vocab_size = len(tokenizer)\n",
    "args.n_gate = len(processor.gating2id) \n",
    "\n",
    "# Slot Meta tokenizing for the decoder initial inputs\n",
    "tokenized_slot_meta = []\n",
    "for slot in slot_meta:\n",
    "    tokenized_slot_meta.append(\n",
    "        tokenizer.encode(slot.replace(\"-\", \" \"), add_special_tokens=False)\n",
    "    )\n",
    "'''각 domain-slot pair를 토크나이징 한다.\n",
    "tokenized_slot_meta[0] = [6728, 21170, 3311, 4112]\n",
    "tokenized_slot_meta[1] = [6728, 6295, 4199, 0]\n",
    "tokenized_slot_meta[2] = [6728, 17502, 6259, 0]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47f79694-a618-4cea-b5b4-416423a193fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import importlib\n",
    "# import model_transformer\n",
    "# importlib.reload(model_transformer)\n",
    "# from model_transformer import TRADE, masked_cross_entropy_for_value\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# # Model 선언\n",
    "# model = TRADE(args, tokenized_slot_meta)\n",
    "# # model.set_subword_embedding(args.model_name_or_path)  # Subword Embedding 초기화\n",
    "# # print(f\"Subword Embeddings is loaded from {args.model_name_or_path}\")\n",
    "# model.to(device)\n",
    "# print(\"Model is initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47dc9c40-8fcb-4c84-9e02-2423202d494d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (537 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hoho\n"
     ]
    }
   ],
   "source": [
    "# gating 갯수 none, dontcare, ptr\n",
    "\n",
    "# Extracting Featrues\n",
    "train_features = processor.convert_examples_to_features(train_examples)\n",
    "'''train_features[2]\n",
    "OpenVocabDSTFeature(guid='snowy-hat-8324:관광_식당_11-2', input_id=[2, 3, 6265, 6672, 4073, 3249, 4034, 8732, 4292, 6722, 4076, 8553, 3, 11655, 4279, 8553, 18, 6336, 4481, 22014, 6771, 4204, 4112, 8538, 4147, 27233, 35, 18790, 4086, 24, 4469, 10749, 14043, 4006, 4073, 4325, 3311, 4112, 6392, 4110, 2734, 4219, 3249, 4576, 6216, 18, 3, 3311, 4116, 4150, 7149, 18790, 4112, 2633, 4151, 4076, 5240, 4050, 6698, 4467, 4029, 4070, 13177, 4479, 4065, 4150, 35, 3, 6698, 4467, 4029, 4034, 9908, 26885, 11684, 25845, 4204, 10561, 18, 2373, 6289, 4279, 4147, 2054, 3249, 4154, 4161, 10397, 35, 3, 2279, 13090, 4192, 2024, 4112, 6249, 4234, 15532, 4403, 4292, 2010, 4219, 4451, 4112, 4244, 4150, 11431, 4221, 4007, 3249, 16868, 4479, 4150, 3], segment_id=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], gating_id=[0, 0, 0, 0, 0, 2, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0], target_ids=[[21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [6336, 4481, 22014, 6771, 4204, 3], [8732, 3, 0, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [6265, 6672, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [93, 6756, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [15532, 4403, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [6265, 6672, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0]])\n",
    "'''\n",
    "dev_features = processor.convert_examples_to_features(dev_examples)\n",
    "'''dev_features[2]\n",
    "OpenVocabDSTFeature(guid='wild-bonus-5601:식당_택시_12-2', input_id=[2, 3, 11655, 4279, 8553, 18, 6265, 10097, 4073, 8117, 4070, 6259, 4283, 26713, 4403, 4292, 3430, 4219, 3249, 4576, 6216, 18, 3, 11655, 4279, 8553, 18, 8863, 6243, 29365, 4034, 27672, 4034, 13177, 2411, 4114, 4065, 4150, 35, 3, 27672, 4034, 14053, 18781, 4150, 18, 3234, 18, 11139, 4147, 10472, 4110, 6477, 4279, 4034, 2084, 10749, 6465, 8161, 10756, 18, 3, 2279, 18, 3084, 5012, 4576, 6216, 18, 8863, 6265, 16417, 4050, 4073, 6767, 4283, 15119, 4083, 4007, 30524, 2084, 4112, 8538, 4147, 27233, 35, 18790, 4112, 24, 18, 23, 10749, 6465, 4608, 6216, 18, 3, 11946, 4279, 17164, 6479, 3757, 4467, 4172, 6304, 7090, 4151, 4076, 4114, 5012, 7933, 35, 3], segment_id=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], gating_id=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], target_ids=[[21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3]])\n",
    "\n",
    "--> gating_id가 전부 0이고 taret_id가 전부 똑같다(전부 'none'임).\n",
    "\n",
    "dev_labels['wild-bonus-5601:식당_택시_12-2'] = ['식당-가격대-dontcare', '식당-지역-서울 북쪽', '식당-종류-중식당', '식당-주차 가능-yes', '식당-주류 판매-yes']\n",
    "\n",
    "'''\n",
    "print('hoho')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fd1f835-8170-48bf-855a-c9367e62c963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# train: 46214\n",
      "# dev: 5031\n"
     ]
    }
   ],
   "source": [
    "args.eval_batch_size = 32\n",
    "\n",
    "\n",
    "train_data = WOSDataset(train_features)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_loader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=args.train_batch_size,\n",
    "    sampler=train_sampler,\n",
    "    collate_fn=processor.collate_fn,\n",
    ")\n",
    "'''collate_fn에서 한 배치안에서 가장 긴 input_id의 길이를 기준으로 다른 input_id를 패딩한다. \n",
    "'''\n",
    "print(\"# train:\", len(train_data))\n",
    "\n",
    "dev_data = WOSDataset(dev_features)\n",
    "dev_sampler = SequentialSampler(dev_data)\n",
    "dev_loader = DataLoader(\n",
    "    dev_data,\n",
    "    batch_size=args.eval_batch_size,\n",
    "    sampler=dev_sampler,\n",
    "    collate_fn=processor.collate_fn,\n",
    ")\n",
    "print(\"# dev:\", len(dev_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58323db7-1007-4ae1-a0ad-5db581e78441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is initialized\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import model_transformer\n",
    "import inference\n",
    "importlib.reload(model_transformer)\n",
    "importlib.reload(inference)\n",
    "from inference import inference\n",
    "from model_transformer import TRADE, masked_cross_entropy_for_value\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Model 선언\n",
    "model = TRADE(args, tokenized_slot_meta)\n",
    "# model.set_subword_embedding(args.model_name_or_path)  # Subword Embedding 초기화\n",
    "# print(f\"Subword Embeddings is loaded from {args.model_name_or_path}\")\n",
    "model.to(device)\n",
    "print(\"Model is initialized\")\n",
    "\n",
    "# Optimizer 및 Scheduler 선언\n",
    "n_epochs = args.num_train_epochs\n",
    "t_total = len(train_loader) * n_epochs\n",
    "warmup_steps = int(t_total * args.warmup_ratio)\n",
    "optimizer = AdamW(model.parameters(), lr=args.learning_rate, eps=args.adam_epsilon)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=warmup_steps, num_training_steps=t_total\n",
    ")\n",
    "\n",
    "loss_fnc_1 = masked_cross_entropy_for_value  # generation\n",
    "loss_fnc_2 = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d98e457-55d9-4ef9-976d-a8aad4671e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## reference하는 변수가 없는 오브젝트들을 gpu 메모리에서 free시킨다.\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1140587-eb60-475e-b677-e06a7b07e556",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 8/158 [01:30<28:23, 11.36s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-f9d0a4f69612>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0meval_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslot_meta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/TRADE_transformer_decoder/inference.py\u001b[0m in \u001b[0;36minference\u001b[0;34m(model, eval_loader, processor, device)\u001b[0m\n\u001b[1;32m     35\u001b[0m         '''\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msegment_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m             '''shape of o : (batch_size, J, max_decoding_step=9, vocab_size = 35000)\n\u001b[1;32m     39\u001b[0m                \u001b[0mshape\u001b[0m \u001b[0mof\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mJ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_slot_gates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/TRADE_transformer_decoder/model_transformer.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, input_ids, max_len, token_type_ids, attention_mask)\u001b[0m\n\u001b[1;32m    106\u001b[0m                                                                    \u001b[0mmax_len\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m                                                                    \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m                                                                    \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m                                                                    )\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/TRADE_transformer_decoder/model_transformer.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, input_ids, max_len, encoder_output, input_masks)\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtrg_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0mdecoder_input_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrg_index\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# (J*batch_size, trg_index+1, hidden_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0mcausal_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_causal_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrg_index\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdecoder_layer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                 decoder_input_temp, _, _ = decoder_layer(decoder_input_temp, \n",
      "\u001b[0;32m~/code/TRADE_transformer_decoder/model_transformer.py\u001b[0m in \u001b[0;36mgenerate_causal_mask\u001b[0;34m(self, size, is_inference)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;31m#             tmp = torch.ones(trg.size(1), trg.size(1), dtype = torch.bool)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m         \u001b[0mcausal_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtril\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcausal_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_score, best_checkpoint = 0, 0\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    for step, batch in enumerate(train_loader):\n",
    "        input_ids, segment_ids, input_masks, gating_ids, target_ids, guids = [\n",
    "            b.to(device) if not isinstance(b, list) else b for b in batch\n",
    "        ] ## b가 list가 아니면 b.to(device)를 하고 b가 list면 그냥 b를 쓴다.\n",
    "\n",
    "        all_point_outputs, all_gate_outputs = model(\n",
    "            input_ids, target_ids, segment_ids, input_masks, \n",
    "        )\n",
    "\n",
    "        # generation loss\n",
    "        loss_1 = loss_fnc_1(\n",
    "            all_point_outputs.contiguous(),\n",
    "            target_ids.contiguous().view(-1),\n",
    "            tokenizer.pad_token_id,\n",
    "        )\n",
    "\n",
    "        # gating loss\n",
    "        loss_2 = loss_fnc_2(\n",
    "            all_gate_outputs.contiguous().view(-1, args.n_gate),\n",
    "            gating_ids.contiguous().view(-1),\n",
    "        )\n",
    "        loss = loss_1 + loss_2\n",
    "\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predictions = inference(model, dev_loader, processor, device)\n",
    "        eval_result = _evaluation(predictions, dev_labels, slot_meta)\n",
    "        torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
